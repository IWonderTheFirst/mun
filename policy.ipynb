{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3957,"sourceType":"datasetVersion","datasetId":2252},{"sourceId":11939481,"sourceType":"datasetVersion","datasetId":7506077},{"sourceId":11963204,"sourceType":"datasetVersion","datasetId":7522543},{"sourceId":11764963,"sourceType":"datasetVersion","datasetId":7379023}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Installing dependencies","metadata":{}},{"cell_type":"code","source":"!pip install node2vec\n!pip install pycountry","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T09:37:15.672625Z","iopub.execute_input":"2025-05-27T09:37:15.672951Z","iopub.status.idle":"2025-05-27T09:37:33.153128Z","shell.execute_reply.started":"2025-05-27T09:37:15.672929Z","shell.execute_reply":"2025-05-27T09:37:33.151986Z"}},"outputs":[{"name":"stdout","text":"Collecting node2vec\n  Downloading node2vec-0.5.0-py3-none-any.whl.metadata (849 bytes)\nRequirement already satisfied: gensim<5.0.0,>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from node2vec) (4.3.3)\nRequirement already satisfied: joblib<2.0.0,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from node2vec) (1.5.0)\nRequirement already satisfied: networkx<4.0.0,>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from node2vec) (3.4.2)\nRequirement already satisfied: numpy<2.0.0,>=1.24.0 in /usr/local/lib/python3.11/dist-packages (from node2vec) (1.26.4)\nRequirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from node2vec) (4.67.1)\nCollecting scipy<1.14.0,>=1.7.0 (from gensim<5.0.0,>=4.3.0->node2vec)\n  Downloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim<5.0.0,>=4.3.0->node2vec) (7.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2.0.0,>=1.24.0->node2vec) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2.0.0,>=1.24.0->node2vec) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2.0.0,>=1.24.0->node2vec) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2.0.0,>=1.24.0->node2vec) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2.0.0,>=1.24.0->node2vec) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2.0.0,>=1.24.0->node2vec) (2.4.1)\nRequirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim<5.0.0,>=4.3.0->node2vec) (1.17.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0.0,>=1.24.0->node2vec) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0.0,>=1.24.0->node2vec) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2.0.0,>=1.24.0->node2vec) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2.0.0,>=1.24.0->node2vec) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2.0.0,>=1.24.0->node2vec) (2024.2.0)\nDownloading node2vec-0.5.0-py3-none-any.whl (7.2 kB)\nDownloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: scipy, node2vec\n  Attempting uninstall: scipy\n    Found existing installation: scipy 1.15.2\n    Uninstalling scipy-1.15.2:\n      Successfully uninstalled scipy-1.15.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\nimbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\nplotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\nmlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed node2vec-0.5.0 scipy-1.13.1\nCollecting pycountry\n  Downloading pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\nDownloading pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pycountry\nSuccessfully installed pycountry-24.6.1\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"speech = \"Free market is an economic system based purely on supply and demand. This quintessential system however is used as a disguise to hide corruption and crony capilaism. It is used to hide a system where companies benefit not from free enterprise but from their relation with the government. Under this disguise of economic liberalization, governments privatize their companies unfairly with low prices, exclusive contracts, and regulatory capture. Corruption in privatization processes undermines economic stability, erodes public trust, and distorts the principles of free market economies. During privatization, government officials may be compelled to give unfair advantages to companies beneficial for themselves. By promoting stock holding disclosure and facilitating random audits, we can improve transparency within nations undergoing significant change. Promoting transparency in crucial in ensuring that privatization happens fairly. Transparency in privatization isn’t just a moral imperative; it is essential in attracting foreign investment and ensuring sustainable economic growth. A vote for this directive is a vote to uphold the values of free market during this critical period of economic transformation\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T09:37:33.154780Z","iopub.execute_input":"2025-05-27T09:37:33.155119Z","iopub.status.idle":"2025-05-27T09:37:33.160134Z","shell.execute_reply.started":"2025-05-27T09:37:33.155090Z","shell.execute_reply":"2025-05-27T09:37:33.159373Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"# Policy Embeddings\nIn this notebook, I vectorized each nation's political stance by:\n- cleaning text\n- embedding country speeches with semantic segmentation and averaging\n- graph based knowledge embedding utilzied country information such as: political bloc, voting record\n- combining vectors","metadata":{}},{"cell_type":"markdown","source":"# Cleaning Text","metadata":{}},{"cell_type":"code","source":"# Function for cleaning data\nimport re\ndef clean_text(text: str) -> str:\n    \"\"\"Clean text by removing country names while preserving stopwords\"\"\"\n\n    country_names = [\n        \"Afghanistan\", \"Albania\", \"Algeria\", \"Andorra\", \"Angola\", \n        \"Antigua\", \"Argentina\", \"Armenia\", \"Australia\", \"Austria\",\n        \"Azerbaijan\", \"Bahamas\", \"Bahrain\", \"Bangladesh\", \"Barbados\",\n        \"Belarus\", \"Belgium\", \"Belize\", \"Benin\", \"Bhutan\",\n        \"Bolivia\", \"Bosnia\", \"Botswana\", \"Brazil\", \"Brunei\",\n        \"Bulgaria\", \"Burkina\", \"Burundi\", \"Cambodia\", \"Cameroon\",\n        \"Canada\", \"Cape Verde\", \"Central African Republic\", \"Chad\", \"Chile\",\n        \"China\", \"Colombia\", \"Comoros\", \"Congo\", \"Costa Rica\",\n        \"Croatia\", \"Cuba\", \"Cyprus\", \"Czech Republic\", \"Denmark\",\n        \"Djibouti\", \"Dominica\", \"Dominican Republic\", \"Ecuador\", \"Egypt\",\n        \"El Salvador\", \"Equatorial Guinea\", \"Eritrea\", \"Estonia\", \"Eswatini\",\n        \"Ethiopia\", \"Fiji\", \"Finland\", \"France\", \"Gabon\",\n        \"Gambia\", \"Georgia\", \"Germany\", \"Ghana\", \"Greece\",\n        \"Grenada\", \"Guatemala\", \"Guinea\", \"Guinea-Bissau\", \"Guyana\",\n        \"Haiti\", \"Honduras\", \"Hungary\", \"Iceland\", \"India\",\n        \"Indonesia\", \"Iran\", \"Iraq\", \"Ireland\", \"Israel\",\n        \"Italy\", \"Ivory Coast\", \"Jamaica\", \"Japan\", \"Jordan\",\n        \"Kazakhstan\", \"Kenya\", \"Kiribati\", \"Korea\", \"Kosovo\",\n        \"Kuwait\", \"Kyrgyzstan\", \"Laos\", \"Latvia\", \"Lebanon\",\n        \"Lesotho\", \"Liberia\", \"Libya\", \"Liechtenstein\", \"Lithuania\",\n        \"Luxembourg\", \"Madagascar\", \"Malawi\", \"Malaysia\", \"Maldives\",\n        \"Mali\", \"Malta\", \"Marshall Islands\", \"Mauritania\", \"Mauritius\",\n        \"Mexico\", \"Micronesia\", \"Moldova\", \"Monaco\", \"Mongolia\",\n        \"Montenegro\", \"Morocco\", \"Mozambique\", \"Myanmar\", \"Namibia\",\n        \"Nauru\", \"Nepal\", \"Netherlands\", \"New Zealand\", \"Nicaragua\",\n        \"Niger\", \"Nigeria\", \"North Korea\", \"North Macedonia\", \"Norway\",\n        \"Oman\", \"Pakistan\", \"Palau\", \"Panama\", \"Papua New Guinea\",\n        \"Paraguay\", \"Peru\", \"Philippines\", \"Poland\", \"Portugal\",\n        \"Qatar\", \"Romania\", \"Russia\", \"Rwanda\", \"Saint Kitts\",\n        \"Saint Lucia\", \"Saint Vincent\", \"Samoa\", \"San Marino\", \"Sao Tome\",\n        \"Saudi Arabia\", \"Senegal\", \"Serbia\", \"Seychelles\", \"Sierra Leone\",\n        \"Singapore\", \"Slovakia\", \"Slovenia\", \"Solomon Islands\", \"Somalia\",\n        \"South Africa\", \"South Korea\", \"South Sudan\", \"Spain\", \"Sri Lanka\",\n        \"Sudan\", \"Suriname\", \"Sweden\", \"Switzerland\", \"Syria\",\n        \"Taiwan\", \"Tajikistan\", \"Tanzania\", \"Thailand\", \"Timor-Leste\",\n        \"Togo\", \"Tonga\", \"Trinidad\", \"Tunisia\", \"Turkey\",\n        \"Turkmenistan\", \"Tuvalu\", \"Uganda\", \"Ukraine\", \"United Arab Emirates\",\n        \"United Kingdom\", \"United States\", \"Uruguay\", \"Uzbekistan\", \"Vanuatu\",\n        \"Vatican City\", \"Venezuela\", \"Vietnam\", \"Yemen\", \"Zambia\", \"Zimbabwe\"\n    ]\n    \n    country_names += [\n        \"USA\", \"UK\", \"UAE\", \"PRC\", \"DPRK\", \n        \"ROK\", \"DRC\", \"U.S.\", \"U.K.\", \"America\",\n        \"Britain\", \"England\", \"Scotland\", \"Wales\", \"Northern Ireland\",\n        \"Hong Kong\", \"Macau\", \"Palestine\", \"Ivory Coast\", \"Czechia\",\n        \"Macedonia\", \"Swaziland\", \"Burma\", \"East Timor\", \"Vatican\"\n    ]\n\n    country_pattern = re.compile(r'\\b(?:' + '|'.join(re.escape(name.lower()) for name in country_names) + r')\\b')\n    text = text.lower()\n    text = country_pattern.sub('', text)\n\n    text = re.sub(r'[^\\w\\s]', '', text)\n    text = re.sub(r'\\b\\d+\\b', '', text)\n    text = ' '.join(text.split()).strip()\n    \n    return text[:3000]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T09:37:33.162115Z","iopub.execute_input":"2025-05-27T09:37:33.162318Z","iopub.status.idle":"2025-05-27T09:37:33.182776Z","shell.execute_reply.started":"2025-05-27T09:37:33.162302Z","shell.execute_reply":"2025-05-27T09:37:33.181825Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# Semantic Segmentation using GPT 4o","metadata":{}},{"cell_type":"code","source":"import json\ndef get_segments(text: str, max_tokens = 200) -> list[str]:\n    paragraphs = [p for p in text.split('\\n') if p.split()]\n\n    num_seg = max(0, len(text.split())//max_tokens) + 3\n    print(f\"Num segments: {num_seg}\")\n    system = f\"\"\"\n    You will do semantic segmentation of the following text and output in a json string list object.\n    The data format should be segments: [jfidfij, jfodfjo, jfodo]\n    Split the text into {num_seg} segments.\n    \"\"\"\n    response = client.chat.completions.create(\n        model='gpt-4o',\n        messages=[\n            {\"role\": \"system\", \"content\": system},\n            {\"role\": \"user\", \"content\": speech}\n        ],\n        response_format={\"type\": \"json_object\"}\n    )\n    \n    segments = json.loads(response.choices[0].message.content)[\"segments\"]\n    if not len(paragraphs) == 1:\n        segments.append(paragraphs)\n    segments.append(text)\n    print(f\"Generated {len(segments)} segments. \")\n    return segments","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T09:37:33.183734Z","iopub.execute_input":"2025-05-27T09:37:33.183973Z","iopub.status.idle":"2025-05-27T09:37:33.207859Z","shell.execute_reply.started":"2025-05-27T09:37:33.183953Z","shell.execute_reply":"2025-05-27T09:37:33.207029Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import pandas as pd\nfrom kaggle_secrets import UserSecretsClient\nfrom openai import AzureOpenAI\nimport os\nfrom openai import OpenAI\n\nuser_secrets = UserSecretsClient()\n\npair_data = pd.read_csv(\"/kaggle/input/inputdata-dataset-10k/pair_data.csv\")\n\napi = user_secrets.get_secret(\"OPENAI_API_KEY\")\nclient = AzureOpenAI(\n    api_key=api,\n    api_version=\"2024-11-01-preview\",\n    azure_endpoint=\"https://swedencentral.api.cognitive.microsoft.com\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T09:38:30.406687Z","iopub.execute_input":"2025-05-27T09:38:30.406985Z","iopub.status.idle":"2025-05-27T09:38:34.796616Z","shell.execute_reply.started":"2025-05-27T09:38:30.406963Z","shell.execute_reply":"2025-05-27T09:38:34.795810Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"# Ensemble Embeddings using text-embedding-3-large & bge-large-en-v1.5","metadata":{}},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer\nfrom sklearn.preprocessing import normalize\nimport numpy as np\n\ndef generate_embeddings(texts: list[str]):\n    stm = SentenceTransformer('BAAI/bge-large-en-v1.5')\n    embeddings = []\n    for i in texts:\n        bge = stm.encode(i)\n        response = client.embeddings.create(\n            model=\"text-embedding-3-large\",\n            input=i\n        )\n        emb1 = normalize([response.data[0].embedding])[0]\n        emb2 = normalize([bge])[0]\n        embedding = np.concatenate([emb1, emb2])\n        embeddings.append(embedding)\n    \n    fin_emb = []\n    \n    for i in range(len(embeddings)):\n        fin_emb.append(list(embeddings[i]))\n    return fin_emb\n\ntexts = get_segments(speech)\nembeddings = generate_embeddings(texts)\nprint(len(embeddings))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T09:38:38.216082Z","iopub.execute_input":"2025-05-27T09:38:38.216513Z","iopub.status.idle":"2025-05-27T09:39:34.081706Z","shell.execute_reply.started":"2025-05-27T09:38:38.216469Z","shell.execute_reply":"2025-05-27T09:39:34.080656Z"}},"outputs":[{"name":"stderr","text":"2025-05-27 09:38:54.757070: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1748338734.999350      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1748338735.066800      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Num segments: 3\nGenerated 4 segments. \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88385cde701949e7bf4c360067a1ab91"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"842302fb67cd41bc9706bfefd82a6678"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/94.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"edc606fe11b94b5fae8038668b97eb67"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d489ed4ee0843cdab0bcc34158f8309"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/779 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0b22f4678624151a5abf60afb8e6554"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2cf01801426c40a49765ae4c4718253e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c555d2f35a84635a1c43d42f66c318f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"430169b41d9447db89f7b1bf6509c6ab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13001fac3b01406e8c3e5d7cb2a63400"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad9a946de4e644c7b12e3e08c6fe5b62"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/191 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"320559a69e7f4901877316fa3d25b731"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bbf965fc69ed48028107aa8dfdf12d1f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25217c960df14eb1a7e2a8bca728d12d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f72d63240a4849569485c5c171dcea77"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47e6233b1b1e4073a3ba28c26eb464f0"}},"metadata":{}},{"name":"stdout","text":"4\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics.pairwise import cosine_similarity\n\nor_encode = np.array(generate_embeddings([speech])[0])\nvec = np.array(embeddings)\nav_vec = np.mean(vec, axis=0)\ntopic_consistency = cosine_similarity(av_vec.reshape(1, -1), or_encode.reshape(1, -1))[0][0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T09:39:34.083452Z","iopub.execute_input":"2025-05-27T09:39:34.083808Z","iopub.status.idle":"2025-05-27T09:39:37.020331Z","shell.execute_reply.started":"2025-05-27T09:39:34.083783Z","shell.execute_reply":"2025-05-27T09:39:37.019346Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7dc361c5c08b49ffa71ae5d096911f1c"}},"metadata":{}}],"execution_count":8},{"cell_type":"markdown","source":"# Knowledge injecting using node graphs","metadata":{}},{"cell_type":"code","source":"import networkx as nx\nfrom itertools import combinations\nfrom node2vec import Node2Vec\n\nimport pandas as pd\n\nIGO = pd.read_csv(\"/kaggle/input/political-igos/Major Political IGOs Expanded.csv\")\nIGO[\"Member Countries\"] = IGO[\"Member Countries\"].apply(lambda x: str(x.split(\"; \")))\n\norganizations = {IGO.iloc[i]['IGO Name'] : IGO.iloc[i]['Member Countries'] for i in range(len(IGO))}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T09:51:53.957942Z","iopub.execute_input":"2025-05-27T09:51:53.958291Z","iopub.status.idle":"2025-05-27T09:51:53.979907Z","shell.execute_reply.started":"2025-05-27T09:51:53.958268Z","shell.execute_reply":"2025-05-27T09:51:53.978992Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"edges = []\nfor members in organizations.values():\n    edges.extend(combinations(members, 2))\n\nG = nx.Graph()\nG.add_edges_from(edges)\n\nnode2vec = Node2Vec(G, dimensions=4096, walk_length=30, num_walks=200, workers=2)\n\nmodel = node2vec.fit(window=10, min_count=1, batch_words=4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T10:00:57.374365Z","iopub.execute_input":"2025-05-27T10:00:57.374772Z","iopub.status.idle":"2025-05-27T10:06:31.533298Z","shell.execute_reply.started":"2025-05-27T10:00:57.374749Z","shell.execute_reply":"2025-05-27T10:06:31.532335Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Computing transition probabilities:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"505a342851bd455e856667fa437f0eba"}},"metadata":{}},{"name":"stderr","text":"Generating walks (CPU: 1): 100%|██████████| 100/100 [00:17<00:00,  5.78it/s]\nGenerating walks (CPU: 2): 100%|██████████| 100/100 [00:17<00:00,  5.84it/s]\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"print(list(model.wv.key_to_index.keys())[:10])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T10:06:31.534629Z","iopub.execute_input":"2025-05-27T10:06:31.534961Z","iopub.status.idle":"2025-05-27T10:06:31.540505Z","shell.execute_reply.started":"2025-05-27T10:06:31.534939Z","shell.execute_reply":"2025-05-27T10:06:31.539513Z"}},"outputs":[{"name":"stdout","text":"['Gabon', 'Djibouti', 'Vanuatu', 'Seychelles', 'Mali', 'Sudan', 'Denmark', 'Nauru', 'Ghana', 'Argentina']\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"import ast\n\n# Convert stringified lists into actual lists\nfor k in organizations:\n    if isinstance(organizations[k], str):\n        organizations[k] = ast.literal_eval(organizations[k])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T09:56:30.928818Z","iopub.execute_input":"2025-05-27T09:56:30.929307Z","iopub.status.idle":"2025-05-27T09:56:30.937306Z","shell.execute_reply.started":"2025-05-27T09:56:30.929277Z","shell.execute_reply":"2025-05-27T09:56:30.935989Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"import pandas as pd\nimport networkx as nx\nfrom itertools import combinations\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport random\n\ndef plot_country_IGO(num: int):\n    country_igos = {}\n    for _, row in IGO.iterrows():\n        for country in row[\"Member Countries\"]:\n            if country not in country_igos:\n                country_igos[country] = []\n            country_igos[country].append(row[\"IGO Name\"])\n    \n    shared_igos = {}\n    countries = list(country_igos.keys())\n    for c1, c2 in combinations(countries, 2):\n        common_igos = set(country_igos[c1]) & set(country_igos[c2])\n        shared_igos[(c1, c2)] = len(common_igos)\n        shared_igos[(c2, c1)] = len(common_igos)\n    \n    G_weighted = nx.Graph()\n    for (c1, c2), weight in shared_igos.items():\n        if weight > 0:\n            G_weighted.add_edge(c1, c2, weight=weight)\n    \n    selected_countries = random.sample(countries, num)\n    \n    adj_matrix = nx.to_numpy_array(G_weighted, nodelist=selected_countries, weight=\"weight\")\n    adj_df = pd.DataFrame(adj_matrix, index=selected_countries, columns=selected_countries)\n    plt.figure(figsize=(15, 12))\n    sns.heatmap(\n        adj_df,\n        cmap=\"YlOrRd\",\n        square=True,\n        linewidths=0.3,\n        annot=True,\n        cbar_kws={\"label\": \"Number of Shared IGOs\"},\n    )\n    \n    plt.title(\"Number of Shared IGO Memberships (30 Random Countries)\", fontsize=16)\n    plt.xlabel(\"Country\", fontsize=12)\n    plt.ylabel(\"Country\", fontsize=12)\n    plt.xticks(rotation=90, fontsize=9)\n    plt.yticks(rotation=0, fontsize=9)\n    plt.tight_layout()\n    plt.show()\n\ndef get_organizations(country: str):\n    return [igo for igo, members in organizations.items() if country in members]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T09:41:28.316868Z","iopub.execute_input":"2025-05-27T09:41:28.317080Z","iopub.status.idle":"2025-05-27T09:41:28.568070Z","shell.execute_reply.started":"2025-05-27T09:41:28.317062Z","shell.execute_reply":"2025-05-27T09:41:28.567278Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"# Generating embeddings for every country speech","metadata":{}},{"cell_type":"code","source":"def get_av_embedding(speech: str):\n    clean_speech = clean_text(speech)\n    segments = get_segments(clean_speech)\n    embeddings = generate_embeddings(segments)\n    vec = np.array(embeddings)\n    return np.mean(vec, axis=0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T09:41:30.707182Z","iopub.execute_input":"2025-05-27T09:41:30.707495Z","iopub.status.idle":"2025-05-27T09:41:30.712443Z","shell.execute_reply.started":"2025-05-27T09:41:30.707464Z","shell.execute_reply":"2025-05-27T09:41:30.711617Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"import pycountry\ndata = pd.read_csv(\"/kaggle/input/un-general-debates/un-general-debates.csv\")\ndata = data.drop(columns=['session', 'year'])\n\ncode_to_country = {country.alpha_3: country.name for country in pycountry.countries}\n\ndata['country'] = data['country'].map(code_to_country)\ndata.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T09:41:30.713516Z","iopub.execute_input":"2025-05-27T09:41:30.714196Z","iopub.status.idle":"2025-05-27T09:41:34.296943Z","shell.execute_reply.started":"2025-05-27T09:41:30.714168Z","shell.execute_reply":"2025-05-27T09:41:34.296228Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"    country                                               text\n0  Maldives  ﻿It is indeed a pleasure for me and the member...\n1   Finland  ﻿\\nMay I begin by congratulating you. Sir, on ...\n2     Niger  ﻿\\nMr. President, it is a particular pleasure ...\n3   Uruguay  ﻿\\nDuring the debate at the fortieth session o...\n4  Zimbabwe  ﻿I should like at the outset to express my del...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>country</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Maldives</td>\n      <td>﻿It is indeed a pleasure for me and the member...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Finland</td>\n      <td>﻿\\nMay I begin by congratulating you. Sir, on ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Niger</td>\n      <td>﻿\\nMr. President, it is a particular pleasure ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Uruguay</td>\n      <td>﻿\\nDuring the debate at the fortieth session o...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Zimbabwe</td>\n      <td>﻿I should like at the outset to express my del...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"# import numpy as np\n# import pandas as pd\n# import openai\n# from collections import defaultdict\n\n# grouped = (\n#     data.groupby(\"country\")\n#     .apply(lambda x: x[\"text\"].tail(5).tolist())\n# )\n\n# country_to_embedding = {}\n\n# for country, speeches in grouped.items():\n#     all_embeddings = [get_av_embedding(speech) for speech in speeches]\n#     avg_embedding = np.mean(all_embeddings, axis=0)\n#     country_to_embedding[country] = avg_embedding.tolist()  # Save as list for serialization","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T09:41:34.297889Z","iopub.execute_input":"2025-05-27T09:41:34.298169Z","iopub.status.idle":"2025-05-27T09:41:34.302533Z","shell.execute_reply.started":"2025-05-27T09:41:34.298150Z","shell.execute_reply":"2025-05-27T09:41:34.301609Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# df = pd.DataFrame(country_to_embedding)\n# df.to_csv(\"/kaggle/working/my_file.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T09:41:34.304990Z","iopub.execute_input":"2025-05-27T09:41:34.305244Z","iopub.status.idle":"2025-05-27T09:41:34.339992Z","shell.execute_reply.started":"2025-05-27T09:41:34.305225Z","shell.execute_reply":"2025-05-27T09:41:34.338973Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/2-hour-speech-embedding-average-5200-speeches/my_file.csv\")\ndf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T09:47:37.611779Z","iopub.execute_input":"2025-05-27T09:47:37.612710Z","iopub.status.idle":"2025-05-27T09:47:37.903795Z","shell.execute_reply.started":"2025-05-27T09:47:37.612676Z","shell.execute_reply":"2025-05-27T09:47:37.902931Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"      Afghanistan   Albania   Algeria   Andorra    Angola  \\\n0       -0.002830 -0.002275 -0.003853 -0.003506 -0.001115   \n1       -0.014219 -0.012174 -0.010564 -0.012624 -0.010476   \n2       -0.011768 -0.011083 -0.012586 -0.012999 -0.012179   \n3       -0.008219 -0.012000 -0.006651 -0.008555 -0.010844   \n4       -0.016086 -0.017030 -0.017446 -0.016143 -0.017607   \n...           ...       ...       ...       ...       ...   \n4091     0.002061  0.005066  0.004410  0.002844  0.003889   \n4092     0.003688  0.000004  0.001837 -0.003209  0.000724   \n4093    -0.009502 -0.007418 -0.008675 -0.007911 -0.010109   \n4094    -0.010405 -0.013699 -0.011363 -0.015361 -0.010800   \n4095     0.023819  0.024319  0.021353  0.023272  0.025818   \n\n      Antigua and Barbuda  Argentina   Armenia  Australia   Austria  ...  \\\n0               -0.002218  -0.005365 -0.002687   0.002012 -0.000911  ...   \n1               -0.010223  -0.010036 -0.011576  -0.012566 -0.014199  ...   \n2               -0.012775  -0.012056 -0.013188  -0.013387 -0.013796  ...   \n3               -0.007830  -0.010371 -0.010527  -0.009601 -0.006244  ...   \n4               -0.018307  -0.018296 -0.016283  -0.019728 -0.017499  ...   \n...                   ...        ...       ...        ...       ...  ...   \n4091             0.004803   0.004737 -0.000585  -0.001856 -0.000996  ...   \n4092             0.002078  -0.002925  0.000019   0.000974  0.000729  ...   \n4093            -0.008621  -0.007242 -0.008291  -0.009096 -0.008522  ...   \n4094            -0.016704  -0.016813 -0.011484  -0.007736 -0.006945  ...   \n4095             0.022673   0.024771  0.024951   0.022565  0.022993  ...   \n\n      United Kingdom  United States   Uruguay  Uzbekistan   Vanuatu  \\\n0           0.003586       0.000595 -0.002140    0.000379 -0.000506   \n1          -0.012159      -0.016181 -0.009929   -0.011209 -0.012978   \n2          -0.012903      -0.013879 -0.012449   -0.012461 -0.012698   \n3          -0.005243      -0.003971 -0.005838   -0.012097 -0.010295   \n4          -0.018312      -0.019540 -0.018404   -0.018047 -0.019902   \n...              ...            ...       ...         ...       ...   \n4091       -0.001049      -0.003648  0.000216   -0.002262 -0.000760   \n4092        0.004469       0.003364  0.002732   -0.000927  0.001899   \n4093       -0.008411      -0.009892 -0.009069   -0.008038 -0.010061   \n4094       -0.005053      -0.006501 -0.011507   -0.009072 -0.013089   \n4095        0.026128       0.022873  0.023081    0.024673  0.022221   \n\n      Venezuela, Bolivarian Republic of  Viet Nam     Yemen    Zambia  \\\n0                             -0.002072 -0.000247  0.004131  0.001895   \n1                             -0.011788 -0.014769 -0.008517 -0.008151   \n2                             -0.013479 -0.012942 -0.012585 -0.012793   \n3                             -0.004901 -0.011390 -0.010391 -0.007997   \n4                             -0.018091 -0.016949 -0.017802 -0.021315   \n...                                 ...       ...       ...       ...   \n4091                          -0.001456  0.000835 -0.006713  0.001614   \n4092                           0.001985  0.000674  0.001287  0.000061   \n4093                          -0.007587 -0.009596 -0.009638 -0.008202   \n4094                          -0.006775 -0.010140 -0.004523 -0.007741   \n4095                           0.022677  0.023916  0.026429  0.023513   \n\n      Zimbabwe  \n0     0.001542  \n1    -0.012103  \n2    -0.013329  \n3    -0.009904  \n4    -0.017591  \n...        ...  \n4091  0.000826  \n4092  0.001017  \n4093 -0.012697  \n4094 -0.006711  \n4095  0.022911  \n\n[4096 rows x 194 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Afghanistan</th>\n      <th>Albania</th>\n      <th>Algeria</th>\n      <th>Andorra</th>\n      <th>Angola</th>\n      <th>Antigua and Barbuda</th>\n      <th>Argentina</th>\n      <th>Armenia</th>\n      <th>Australia</th>\n      <th>Austria</th>\n      <th>...</th>\n      <th>United Kingdom</th>\n      <th>United States</th>\n      <th>Uruguay</th>\n      <th>Uzbekistan</th>\n      <th>Vanuatu</th>\n      <th>Venezuela, Bolivarian Republic of</th>\n      <th>Viet Nam</th>\n      <th>Yemen</th>\n      <th>Zambia</th>\n      <th>Zimbabwe</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.002830</td>\n      <td>-0.002275</td>\n      <td>-0.003853</td>\n      <td>-0.003506</td>\n      <td>-0.001115</td>\n      <td>-0.002218</td>\n      <td>-0.005365</td>\n      <td>-0.002687</td>\n      <td>0.002012</td>\n      <td>-0.000911</td>\n      <td>...</td>\n      <td>0.003586</td>\n      <td>0.000595</td>\n      <td>-0.002140</td>\n      <td>0.000379</td>\n      <td>-0.000506</td>\n      <td>-0.002072</td>\n      <td>-0.000247</td>\n      <td>0.004131</td>\n      <td>0.001895</td>\n      <td>0.001542</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.014219</td>\n      <td>-0.012174</td>\n      <td>-0.010564</td>\n      <td>-0.012624</td>\n      <td>-0.010476</td>\n      <td>-0.010223</td>\n      <td>-0.010036</td>\n      <td>-0.011576</td>\n      <td>-0.012566</td>\n      <td>-0.014199</td>\n      <td>...</td>\n      <td>-0.012159</td>\n      <td>-0.016181</td>\n      <td>-0.009929</td>\n      <td>-0.011209</td>\n      <td>-0.012978</td>\n      <td>-0.011788</td>\n      <td>-0.014769</td>\n      <td>-0.008517</td>\n      <td>-0.008151</td>\n      <td>-0.012103</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.011768</td>\n      <td>-0.011083</td>\n      <td>-0.012586</td>\n      <td>-0.012999</td>\n      <td>-0.012179</td>\n      <td>-0.012775</td>\n      <td>-0.012056</td>\n      <td>-0.013188</td>\n      <td>-0.013387</td>\n      <td>-0.013796</td>\n      <td>...</td>\n      <td>-0.012903</td>\n      <td>-0.013879</td>\n      <td>-0.012449</td>\n      <td>-0.012461</td>\n      <td>-0.012698</td>\n      <td>-0.013479</td>\n      <td>-0.012942</td>\n      <td>-0.012585</td>\n      <td>-0.012793</td>\n      <td>-0.013329</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.008219</td>\n      <td>-0.012000</td>\n      <td>-0.006651</td>\n      <td>-0.008555</td>\n      <td>-0.010844</td>\n      <td>-0.007830</td>\n      <td>-0.010371</td>\n      <td>-0.010527</td>\n      <td>-0.009601</td>\n      <td>-0.006244</td>\n      <td>...</td>\n      <td>-0.005243</td>\n      <td>-0.003971</td>\n      <td>-0.005838</td>\n      <td>-0.012097</td>\n      <td>-0.010295</td>\n      <td>-0.004901</td>\n      <td>-0.011390</td>\n      <td>-0.010391</td>\n      <td>-0.007997</td>\n      <td>-0.009904</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.016086</td>\n      <td>-0.017030</td>\n      <td>-0.017446</td>\n      <td>-0.016143</td>\n      <td>-0.017607</td>\n      <td>-0.018307</td>\n      <td>-0.018296</td>\n      <td>-0.016283</td>\n      <td>-0.019728</td>\n      <td>-0.017499</td>\n      <td>...</td>\n      <td>-0.018312</td>\n      <td>-0.019540</td>\n      <td>-0.018404</td>\n      <td>-0.018047</td>\n      <td>-0.019902</td>\n      <td>-0.018091</td>\n      <td>-0.016949</td>\n      <td>-0.017802</td>\n      <td>-0.021315</td>\n      <td>-0.017591</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4091</th>\n      <td>0.002061</td>\n      <td>0.005066</td>\n      <td>0.004410</td>\n      <td>0.002844</td>\n      <td>0.003889</td>\n      <td>0.004803</td>\n      <td>0.004737</td>\n      <td>-0.000585</td>\n      <td>-0.001856</td>\n      <td>-0.000996</td>\n      <td>...</td>\n      <td>-0.001049</td>\n      <td>-0.003648</td>\n      <td>0.000216</td>\n      <td>-0.002262</td>\n      <td>-0.000760</td>\n      <td>-0.001456</td>\n      <td>0.000835</td>\n      <td>-0.006713</td>\n      <td>0.001614</td>\n      <td>0.000826</td>\n    </tr>\n    <tr>\n      <th>4092</th>\n      <td>0.003688</td>\n      <td>0.000004</td>\n      <td>0.001837</td>\n      <td>-0.003209</td>\n      <td>0.000724</td>\n      <td>0.002078</td>\n      <td>-0.002925</td>\n      <td>0.000019</td>\n      <td>0.000974</td>\n      <td>0.000729</td>\n      <td>...</td>\n      <td>0.004469</td>\n      <td>0.003364</td>\n      <td>0.002732</td>\n      <td>-0.000927</td>\n      <td>0.001899</td>\n      <td>0.001985</td>\n      <td>0.000674</td>\n      <td>0.001287</td>\n      <td>0.000061</td>\n      <td>0.001017</td>\n    </tr>\n    <tr>\n      <th>4093</th>\n      <td>-0.009502</td>\n      <td>-0.007418</td>\n      <td>-0.008675</td>\n      <td>-0.007911</td>\n      <td>-0.010109</td>\n      <td>-0.008621</td>\n      <td>-0.007242</td>\n      <td>-0.008291</td>\n      <td>-0.009096</td>\n      <td>-0.008522</td>\n      <td>...</td>\n      <td>-0.008411</td>\n      <td>-0.009892</td>\n      <td>-0.009069</td>\n      <td>-0.008038</td>\n      <td>-0.010061</td>\n      <td>-0.007587</td>\n      <td>-0.009596</td>\n      <td>-0.009638</td>\n      <td>-0.008202</td>\n      <td>-0.012697</td>\n    </tr>\n    <tr>\n      <th>4094</th>\n      <td>-0.010405</td>\n      <td>-0.013699</td>\n      <td>-0.011363</td>\n      <td>-0.015361</td>\n      <td>-0.010800</td>\n      <td>-0.016704</td>\n      <td>-0.016813</td>\n      <td>-0.011484</td>\n      <td>-0.007736</td>\n      <td>-0.006945</td>\n      <td>...</td>\n      <td>-0.005053</td>\n      <td>-0.006501</td>\n      <td>-0.011507</td>\n      <td>-0.009072</td>\n      <td>-0.013089</td>\n      <td>-0.006775</td>\n      <td>-0.010140</td>\n      <td>-0.004523</td>\n      <td>-0.007741</td>\n      <td>-0.006711</td>\n    </tr>\n    <tr>\n      <th>4095</th>\n      <td>0.023819</td>\n      <td>0.024319</td>\n      <td>0.021353</td>\n      <td>0.023272</td>\n      <td>0.025818</td>\n      <td>0.022673</td>\n      <td>0.024771</td>\n      <td>0.024951</td>\n      <td>0.022565</td>\n      <td>0.022993</td>\n      <td>...</td>\n      <td>0.026128</td>\n      <td>0.022873</td>\n      <td>0.023081</td>\n      <td>0.024673</td>\n      <td>0.022221</td>\n      <td>0.022677</td>\n      <td>0.023916</td>\n      <td>0.026429</td>\n      <td>0.023513</td>\n      <td>0.022911</td>\n    </tr>\n  </tbody>\n</table>\n<p>4096 rows × 194 columns</p>\n</div>"},"metadata":{}}],"execution_count":18},{"cell_type":"markdown","source":"# Combining speech embeddings and knowledge based embeddings","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\nfrom torch.utils.data import DataLoader, TensorDataset\n\nclass ProjectionMLP(nn.Module):\n    def __init__(self, input_dim, output_dim=512):\n        super().__init__()\n        self.projection = nn.Sequential(\n            nn.Linear(input_dim, 1024),\n            nn.ReLU(),\n            nn.Linear(1024, output_dim)\n        )\n\n    def forward(self, x):\n        return self.projection(x)\n\n# Replace with your real embeddings\nspeech_embeddings = np.load(\"speech_embeddings.npy\")     # shape (N, d_speech)\ngraph_embeddings = np.load(\"graph_embeddings.npy\")       # shape (N, d_graph)\n\n# Convert to torch tensors\nspeech_tensor = torch.tensor(speech_embeddings, dtype=torch.float32)\ngraph_tensor = torch.tensor(graph_embeddings, dtype=torch.float32)\n\ndataset = TensorDataset(speech_tensor, graph_tensor)\ndataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n\nd_speech = speech_tensor.shape[1]\nd_graph = graph_tensor.shape[1]\n\nspeech_proj = ProjectionMLP(d_speech)\ngraph_proj = ProjectionMLP(d_graph)\n\noptimizer = torch.optim.Adam(list(speech_proj.parameters()) + list(graph_proj.parameters()), lr=1e-3)\n\ndef contrastive_loss(proj1, proj2, temperature=0.07):\n    \"\"\"\n    NT-Xent Loss (SimCLR-style)\n    proj1: shape (B, D)\n    proj2: shape (B, D)\n    \"\"\"\n    batch_size = proj1.shape[0]\n    proj1 = F.normalize(proj1, dim=1)\n    proj2 = F.normalize(proj2, dim=1)\n\n    representations = torch.cat([proj1, proj2], dim=0)  # (2B, D)\n    similarity_matrix = torch.matmul(representations, representations.T)  # (2B, 2B)\n\n    # Create labels\n    labels = torch.cat([torch.arange(batch_size) + batch_size, torch.arange(batch_size)], dim=0)\n    labels = labels.to(proj1.device)\n\n    # Mask self-similarity\n    mask = torch.eye(2 * batch_size, dtype=torch.bool).to(proj1.device)\n    similarity_matrix = similarity_matrix[~mask].view(2 * batch_size, -1)\n\n    logits = similarity_matrix / temperature\n    loss = F.cross_entropy(logits, labels)\n    return loss\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}